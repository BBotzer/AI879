{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Brandon Botzer\n",
    "# Date: 3/30/2024\n",
    "# Class: Penn State - AI 879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "\n",
    "    Problem:\n",
    "\n",
    "    Take a set of at least five pictures of an object from a slightly different angle (preferably 15 degrees between the pictures). Calculate the distance to the object in different pairs of consecutive pictures by triangulation and compare the result to the distance observed. Show the result.\n",
    "    Note: if you get receiving an undefined variable error for 'storedParams', you should build your own “stereoParameters” object using the following: parameters for the camera, offset of the camera when you took the pictures, and a true representation of the object of interest. To determine the parameters of the camera (\"cameraParameters\"), use the images that you have taken. On each of these images, select a number of corresponding points that reflect the object of interest (It can be some corners, or center of a circle, etc)  and build the corresponding matrices with their positions. Similarly, mark the corresponding points  in the true representation of the object of interest and save it in its own matrix. Having this, you can build the “cameraParameters” object.using the two generated matrices. To create the “stereoParameters” object, make sure that you measure the offset and rotation of the camera positions With this object, you can triangulate. Look into the examples on the following MATLAB pages:  \"triangulate\", \"stereoParameters\" and \"cameraParameters\".\n",
    "\n",
    "    A better option is to train your cameraParameters on a checkered pattern.\n",
    "\n",
    "Links to an external site.\", \"stereoParameters Links to an external site.\" and \"cameraParameters Links to an external site.\".\n",
    "A better option is to train your \"cameraParameters Links to an external site.\" object on a checkered pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for functions\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import skimage as ski\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "# Showing the results of scipy computations\n",
    "import pandas as pd\n",
    "\n",
    "cv.__version__, ski.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the two clock images from the online class notes\n",
    "im1_o = ski.io.imread('L13_clock3.jpg')\n",
    "im2_o = ski.io.imread('L13_clock4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The step 1 of calibrating the camera (at both positions!)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ..., (6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Load calibration images\n",
    "images = glob.glob('calibration_images/*.jpg')\n",
    "\n",
    "# Iterate through calibration images\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6), None)\n",
    "\n",
    "    # If corners are found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display corners\n",
    "        img = cv2.drawChessboardCorners(img, (7,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Perform camera calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Print calibration results\n",
    "print(\"Camera Matrix:\")\n",
    "print(mtx)\n",
    "print(\"\\nDistortion Coefficients:\")\n",
    "print(dist)\n",
    "\n",
    "# Save calibration parameters for later use\n",
    "np.savez('camera_calibration_params.npz', mtx=mtx, dist=dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Camera Calibration\n",
    "# Load calibration data or calibrate using a chessboard pattern\n",
    "\n",
    "# Step 2: Rectify the Images\n",
    "# Load the images\n",
    "img1 = cv2.imread('image1.jpg')\n",
    "img2 = cv2.imread('image2.jpg')\n",
    "\n",
    "# Load calibration parameters (intrinsic and extrinsic)\n",
    "# This can be obtained from camera calibration or stereo calibration\n",
    "# stereoRectify will provide rectification matrices and disparity-to-depth mapping matrix\n",
    "# Note: You may also need to specify the baseline distance between the cameras\n",
    "R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(\n",
    "    cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T)\n",
    "\n",
    "# Rectify the images\n",
    "map1, map2 = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "rectified_img1 = cv2.remap(img1, map1, map2, cv2.INTER_LINEAR)\n",
    "rectified_img2 = cv2.remap(img2, map1, map2, cv2.INTER_LINEAR)\n",
    "\n",
    "# Step 3: Compute Disparity Map\n",
    "# Perform stereo matching to compute the disparity map\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(rectified_img1, rectified_img2)\n",
    "\n",
    "# Step 4: Calculate Depth Map\n",
    "# Compute the depth map using the disparity map and Q matrix\n",
    "depth_map = cv2.reprojectImageTo3D(disparity, Q)\n",
    "\n",
    "# Now you can extract depth information from the depth map\n",
    "# For example, get depth at a specific pixel location (x, y)\n",
    "x, y = 100, 100\n",
    "depth = depth_map[y, x]\n",
    "\n",
    "print(\"Depth at pixel ({}, {}): {:.2f} meters\".format(x, y, depth[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangulation Methods:\n",
    "http://users.cecs.anu.edu.au/~hartley/Papers/triangulation/triangulation.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
